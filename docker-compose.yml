# docker-compose.yml
# FLEAD: Federated Learning Edge-AI & Data pipeline


services:
  # -------------------------------------------------
  # 0) DATA PREPROCESSOR (Kaggle + CSV/chunks generator)
  # -------------------------------------------------
  data-preprocessor:
    build:
      context: .
      dockerfile: docker/Dockerfile.data-preprocessor
    container_name: data-preprocessor
    working_dir: /app
    command: >
      bash -lc
      "python scripts/data_preprocessor.py &&
       python scripts/convert_chunks_to_device_csvs.py"
    environment:
      KAGGLE_CONFIG_DIR: /root/.kaggle
    volumes:
      - ./data:/app/data
      - ./kaggle:/root/.kaggle:ro
    networks:
      - flead_network
    restart: "no"

  # -------------------------------------------------
  # 0b) JUPYTER DEV UI (optional, for inspecting notebooks)
  # -------------------------------------------------
  jupyter-dev:
    build:
      context: ./docker          # üëà build from docker/ folder
      dockerfile: Dockerfile.jupyter-dev
    container_name: jupyter-dev
    working_dir: /app
    volumes:
      - .:/app
      - ./kaggle:/root/.kaggle:ro
    environment:
      KAGGLE_CONFIG_DIR: /root/.kaggle
    ports:
      - "8888:8888"
    networks:
      - flead_network
    restart: "no"



  # -------------------------------------------------
  # 1) KAFKA MULTI-BROKER CLUSTER (KRaft mode)
  # -------------------------------------------------
  kafka-broker-1:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-broker-1
    ports:
      - "9092:9092"    # external client port (broker 1)
      - "29092:29092"  # optional extra port (not used by listeners, ok to keep)
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: "broker,controller"

      # REQUIRED by Confluent KRaft entrypoint
      CLUSTER_ID: "DrFOBqf2SYmi0Qu1eq13kw"

      # KRaft quorum (all 4 controllers)
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-broker-1:29093,2@kafka-broker-2:29093,3@kafka-broker-3:29093,4@kafka-broker-4:29093"

      # Listeners: data + controller
      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-broker-1:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # Internal topics & group coordination
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

      # Data dir
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

    volumes:
      - kafka_broker_1_data:/var/lib/kafka/data
    networks:
      - flead_network
    healthcheck:
      test: ["CMD", "bash", "-c", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 40s

  kafka-broker-2:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-broker-2
    ports:
      - "9093:9092"    # external client port (broker 2)
      - "29093:29093"  # exposes controller port if you ever need it
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: "broker,controller"
      CLUSTER_ID: "DrFOBqf2SYmi0Qu1eq13kw"

      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-broker-1:29093,2@kafka-broker-2:29093,3@kafka-broker-3:29093,4@kafka-broker-4:29093"

      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-broker-2:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

    volumes:
      - kafka_broker_2_data:/var/lib/kafka/data
    networks:
      - flead_network

  kafka-broker-3:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-broker-3
    ports:
      - "9094:9092"    # external client port (broker 3)
      - "29094:29093"  # map host 29094 -> container 29093 (controller)
    environment:
      KAFKA_NODE_ID: 3
      KAFKA_PROCESS_ROLES: "broker,controller"
      CLUSTER_ID: "DrFOBqf2SYmi0Qu1eq13kw"

      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-broker-1:29093,2@kafka-broker-2:29093,3@kafka-broker-3:29093,4@kafka-broker-4:29093"

      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-broker-3:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

    volumes:
      - kafka_broker_3_data:/var/lib/kafka/data
    networks:
      - flead_network

  kafka-broker-4:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-broker-4
    ports:
      - "9095:9092"    # external client port (broker 4)
      - "29095:29093"  # map host 29095 -> container 29093 (controller)
    environment:
      KAFKA_NODE_ID: 4
      KAFKA_PROCESS_ROLES: "broker,controller"
      CLUSTER_ID: "DrFOBqf2SYmi0Qu1eq13kw"

      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-broker-1:29093,2@kafka-broker-2:29093,3@kafka-broker-3:29093,4@kafka-broker-4:29093"

      KAFKA_LISTENERS: "PLAINTEXT://:9092,CONTROLLER://:29093"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka-broker-4:9092"
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_DIRS: "/var/lib/kafka/data"

    volumes:
      - kafka_broker_4_data:/var/lib/kafka/data
    networks:
      - flead_network


  # -------------------------------------------------
  # 2) TIMESCALEDB + INIT
  # -------------------------------------------------
  timescaledb:
    image: timescale/timescaledb:2.15.1-pg14
    container_name: timescaledb
    environment:
      POSTGRES_DB: flead
      POSTGRES_USER: flead
      POSTGRES_PASSWORD: password
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
    networks:
      - flead_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -h localhost -U $${POSTGRES_USER} -d $${POSTGRES_DB} || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 15
      start_period: 60s


  database-init:
    build:
      context: .
      dockerfile: docker/Dockerfile.database-init
    container_name: database-init
    environment:
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: flead
      DB_USER: flead
      DB_PASSWORD: password
    depends_on:
      timescaledb:
        condition: service_healthy
    networks:
      - flead_network
    restart: "no"

  timescaledb-collector:
    build:
      context: .
    #   dockerfile: docker/Dockerfile.timescaledb-collector  # (keep if custom)
      dockerfile: docker/Dockerfile.timescaledb-collector
    container_name: timescaledb-collector
    environment:
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: flead
      DB_USER: flead
      DB_PASSWORD: password
      # IMPORTANT: bootstrap on PLAINTEXT ports, not controller ports
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
    depends_on:
      timescaledb:
        condition: service_healthy
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
    networks:
      - flead_network
    restart: unless-stopped
    

# -------------------------------------------------
# 3) FLINK CLUSTER
# -------------------------------------------------
  flink-jobmanager:
    build:
      context: .
      dockerfile: docker/Dockerfile.flink
    container_name: flink-jobmanager
    command: jobmanager
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      JOB_MANAGER_RPC_PORT: 6123
      TASK_MANAGER_RPC_PORT: 6122
      TASK_MANAGER_MEMORY_PROCESS_SIZE: 1024m
      JOB_MANAGER_MEMORY_PROCESS_SIZE: 1024m
      # Used by 03_flink_local_training.py
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
      # Where to store local models inside the container
      LOCAL_MODEL_DIR: "/opt/flink/models/local"
    ports:
      - "6123:6123"
      - "8161:8081"       # Flink dashboard
    volumes:
      - flink_jobmanager_data:/flink/data
      - ./scripts:/opt/flink/scripts      # Python Flink jobs
      - ./data:/opt/flink/data            # Optional input data
      # üîπ Only mount custom jars into usrlib, do NOT touch /opt/flink/lib
      - ./flink-jars:/opt/flink/usrlib
    networks:
      - flead_network
    depends_on:
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started

  flink-taskmanager:
    build:
      context: .
      dockerfile: docker/Dockerfile.flink
    container_name: flink-taskmanager
    command: taskmanager
    environment:
      JOB_MANAGER_RPC_ADDRESS: flink-jobmanager
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
      LOCAL_MODEL_DIR: "/opt/flink/models/local"
    volumes:
      # Same user jars as jobmanager
      - ./flink-jars:/opt/flink/usrlib
    depends_on:
      flink-jobmanager:
        condition: service_started
    networks:
      - flead_network


  # -------------------------------------------------
  # 4) SPARK CLUSTER
  # -------------------------------------------------
  spark-master:
    build:
      context: .
      dockerfile: docker/Dockerfile.spark
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      SPARK_NO_DAEMONIZE: "1"
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    ports:
      - "8086:8080"
      - "7077:7077"
    volumes:
      - spark_master_data:/opt/spark/work
      - ./scripts:/opt/spark/scripts
      - ./data:/opt/spark/data
      # Shared global model directory (for Spark Analytics to read)
      - models_global:/app/models/global
    networks:
      - flead_network
    depends_on:
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
      timescaledb:
        condition: service_healthy

  spark-worker-1:
    build:
      context: .
      dockerfile: docker/Dockerfile.spark
    container_name: spark-worker-1
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_NO_DAEMONIZE: "1"
    volumes:
      - spark_worker_data:/opt/spark/work
    depends_on:
      spark-master:
        condition: service_started
    networks:
      - flead_network
    ports:
      - "8087:8081"    # ‚Üê add this line

  # -------------------------------------------------
  # 5) KAFKA UI
  # -------------------------------------------------
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8081:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: flead
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
    depends_on:
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
    networks:
      - flead_network

  # -------------------------------------------------
  # 6) MULTI-BROKER PRODUCER
  # -------------------------------------------------
  kafka-producer:
    build:
      context: .
      dockerfile: docker/Dockerfile.producer
    container_name: kafka-producer
    command: [
      "python", "scripts/02_kafka_producer_multi_broker.py",
      "--source", "data/processed",
      "--rate", "10",
      "--topic", "edge-iiot-stream"
    ]
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
    depends_on:
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
    networks:
      - flead_network
    restart: unless-stopped


  # -------------------------------------------------
  # 7) FEDERATED AGGREGATION SERVICE
  # -------------------------------------------------
  federated-aggregator:
    build:
      context: .
      dockerfile: docker/Dockerfile.aggregator
    container_name: federated-aggregator
    environment:
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
      TIMESCALEDB_HOST: timescaledb
      TIMESCALEDB_PORT: 5432
      TIMESCALEDB_DB: flead
      TIMESCALEDB_USER: flead
      TIMESCALEDB_PASSWORD: password
    volumes:
      # Shared global model directory for saving global_model_v*.pkl
      - models_global:/app/models/global
    depends_on:
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
      timescaledb:
        condition: service_healthy
    networks:
      - flead_network
    restart: unless-stopped

  # -------------------------------------------------
  # 7b) SPARK ANALYTICS ‚Äì DASHBOARD METRICS UPDATER
  # -------------------------------------------------
  spark-analytics:
    build:
      context: .
      # Reuse a Python image that already has psycopg2 etc.
      # The aggregator image is fine for this:
      dockerfile: docker/Dockerfile.aggregator
    container_name: spark-analytics
    command: ["python", "scripts/dashboard_metrics_updater.py"]
    depends_on:
      timescaledb:
        condition: service_healthy
      database-init:
        condition: service_completed_successfully
      federated-aggregator:
        condition: service_started
    networks:
      - flead_network
    restart: unless-stopped


  # -------------------------------------------------
  # 8) DEVICE VIEWER (FLASK APP)
  # -------------------------------------------------
  device-viewer:
    build:
      context: .
      dockerfile: docker/Dockerfile.device-viewer
    container_name: device-viewer
    ports:
      - "8082:5000"
    environment:
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: flead
      DB_USER: flead
      DB_PASSWORD: password
      PORT: 5000
    depends_on:
      timescaledb:
        condition: service_healthy
    networks:
      - flead_network
    restart: unless-stopped

  # -------------------------------------------------
  # 9) MONITORING DASHBOARD (FLASK)
  # -------------------------------------------------
  monitoring-dashboard:
    build:
      context: .
      dockerfile: docker/Dockerfile.monitoring-dashboard
    container_name: monitoring-dashboard
    ports:
      - "5001:5000"
    environment:
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: flead
      DB_USER: flead
      DB_PASSWORD: password
      KAFKA_BOOTSTRAP_SERVERS: "kafka-broker-1:9092,kafka-broker-2:9092,kafka-broker-3:9092,kafka-broker-4:9092"
    depends_on:
      timescaledb:
        condition: service_healthy
      kafka-broker-1:
        condition: service_started
      kafka-broker-2:
        condition: service_started
      kafka-broker-3:
        condition: service_started
      kafka-broker-4:
        condition: service_started
    networks:
      - flead_network
    restart: unless-stopped

  # -------------------------------------------------
  # 10) GRAFANA + INIT
  # -------------------------------------------------
  grafana:
    image: grafana/grafana:11.0.0
    container_name: grafana
    ports:
      - "3001:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    depends_on:
      timescaledb:
        condition: service_healthy
    networks:
      - flead_network

  grafana-init:
    build:
      context: .
      dockerfile: docker/Dockerfile.grafana-init
    container_name: grafana-init
    environment:
      GRAFANA_URL: http://grafana:3000
      GRAFANA_USER: admin
      GRAFANA_PASSWORD: admin
      DB_HOST: timescaledb
      DB_PORT: 5432
      DB_NAME: flead
      DB_USER: flead
      DB_PASSWORD: password
    depends_on:
      grafana:
        condition: service_started
      database-init:
        condition: service_completed_successfully
    networks:
      - flead_network
    restart: "no"

# ---------------------------------------------------
# Networks & volumes
# ---------------------------------------------------
networks:
  flead_network:
    driver: bridge

volumes:
  kafka_broker_1_data:
  kafka_broker_2_data:
  kafka_broker_3_data:
  kafka_broker_4_data:
  timescaledb_data:
  flink_jobmanager_data:
  flink_taskmanager_data:
  spark_master_data:
  spark_worker_data:
  grafana_data:
  # Shared volume for global model snapshots, used by:
  #   - federated-aggregator (writer)
  #   - spark-master (reader in 05_spark_analytics.py)
  models_global:
