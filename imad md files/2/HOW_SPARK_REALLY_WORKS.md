# ğŸ” How Spark Analytics Actually Works (Step by Step)

## The Real Data Flow in Spark

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         KAFKA REAL-TIME STREAM                            â”‚
â”‚                      (edge-iiot-stream topic)                             â”‚
â”‚                                                                            â”‚
â”‚  {"device_id": "device_0", "timestamp": "2025-11-07T10:30:00.123",       â”‚
â”‚   "temperature": 72.5, "humidity": 45.2, "pressure": 1013.25}            â”‚
â”‚                                                                            â”‚
â”‚  Every millisecond: ~1000+ devices sending data                          â”‚
â”‚  Data rate: ~12,000 IoT events per second                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  SPARK READSTREAM     â”‚
                        â”‚  (Structured Stream)  â”‚
                        â”‚  Reads from Kafka     â”‚
                        â”‚  Unbounded data       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                                       â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  BATCH PATH     â”‚                              â”‚   STREAM PATH        â”‚
   â”‚  (Historical)   â”‚                              â”‚   (Real-time)        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                                                    â†“
   Read CSV files                                   Parse JSON from Kafka
   /opt/spark/data/processed/*.csv                 Schema:
                                                    - device_id (string)
   Every CSV has:                                   - timestamp (string)
   - device_id                                      - data (double)
   - timestamp
   - temperature/sensor values
                                                    Add watermark:
   Daily aggregation:                               "Allow 1 minute late data"
   â”œâ”€ AVG(temperature)
   â”œâ”€ MIN(temperature)
   â”œâ”€ MAX(temperature)
   â”œâ”€ STDDEV(temperature)
   â””â”€ COUNT(rows)

   Store to:
   batch_analysis_results table
                                                    â†“
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  WINDOWING (30s)     â”‚
                                         â”‚  Aggregate data into â”‚
                                         â”‚  30-second buckets   â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â†“
                                         Window 1: [10:30:00-10:30:30]
                                         - avg(temperature)
                                         - stddev(temperature)

                                         Window 2: [10:30:30-10:31:00]
                                         - avg(temperature)
                                         - stddev(temperature)

                                         (Continuous windows!)
                                                    â†“
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  ANOMALY DETECTION   â”‚
                                         â”‚  Calculate Z-score   â”‚
                                         â”‚  Z = (X - Î¼) / Ïƒ     â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â†“
                                         If Z > 2.5:
                                         - anomaly = TRUE
                                         - confidence = Z-score value

                                         Store to:
                                         stream_analysis_results
                                                    â†“
                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                         â”‚  GLOBAL MODEL EVALUATION     â”‚
                                         â”‚  (THIS IS THE REAL PART!)    â”‚
                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                                            â”‚
                    â†“                                                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ 1. Load Global Model â”‚                                  â”‚ 2. Make Prediction  â”‚
        â”‚                      â”‚                                  â”‚                     â”‚
        â”‚ path: /app/models/   â”‚                                  â”‚ model.predict(data) â”‚
        â”‚ global/latest_model  â”‚                                  â”‚ â†’ prediction_result â”‚
        â”‚                      â”‚                                  â”‚   (0.85, 0.92,     â”‚
        â”‚ Contains:            â”‚                                  â”‚    0.78, etc.)      â”‚
        â”‚ - model weights      â”‚                                  â”‚                     â”‚
        â”‚ - version (v1, v2...) â”‚                                 â”‚                     â”‚
        â”‚ - accuracy metadata  â”‚                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â†“
                    â†“                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                          â”‚ 3. Compare Actual  â”‚
                    â”‚                                          â”‚                     â”‚
                    â”‚                                          â”‚ prediction: 0.85    â”‚
                    â”‚                                          â”‚ actual: 0.92        â”‚
                    â”‚                                          â”‚                     â”‚
                    â”‚                                          â”‚ is_correct? NO!     â”‚
                    â”‚                                          â”‚ error: 0.07         â”‚
                    â”‚                                          â”‚ loss: 0.0049        â”‚
                    â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                                    â†“
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  4. Store Evaluation     â”‚
                                    â”‚                          â”‚
                                    â”‚  INSERT INTO             â”‚
                                    â”‚  model_evaluations:      â”‚
                                    â”‚  - model_version: v1     â”‚
                                    â”‚  - device_id: device_0   â”‚
                                    â”‚  - prediction_result: 0.85
                                    â”‚  - actual_result: 0.92   â”‚
                                    â”‚  - is_correct: false     â”‚
                                    â”‚  - confidence: 0.92      â”‚
                                    â”‚  - model_accuracy: 75%   â”‚
                                    â”‚                          â”‚
                                    â”‚ âœ“ REAL DATA STORED!      â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â†“
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚  5. This Goes to         â”‚
                                    â”‚  Federated Server!       â”‚
                                    â”‚                          â”‚
                                    â”‚  "Hey, Global v1 had:    â”‚
                                    â”‚   - 1000 predictions     â”‚
                                    â”‚   - 750 were correct     â”‚
                                    â”‚   - Real accuracy: 75%"  â”‚
                                    â”‚                          â”‚
                                    â”‚ NOT: "accuracy formula   â”‚
                                    â”‚      says 74%"           â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Spark's Real Evaluation Process (Detailed)

### What Data Spark Actually Has Access To:

```
Kafka Stream: Real IoT data
â”œâ”€ device_0 sends: temperature = 72.5Â°C at 10:30:00.123
â”œâ”€ device_1 sends: temperature = 71.8Â°C at 10:30:00.456
â”œâ”€ device_234 sends: temperature = 73.2Â°C at 10:30:01.001
â””â”€ ... 2,407 devices sending per second

â†“

Spark receives BOTH:
1. Current sensor values (what devices are reading)
2. Global model predictions (what model thinks they should be)

â†“

Comparison:
Device_0:
  â”œâ”€ Actual reading: 72.5Â°C â† GROUND TRUTH
  â”œâ”€ Model prediction: 72.1Â°C â† MODEL OUTPUT
  â”œâ”€ Difference: 0.4Â°C â† ERROR
  â””â”€ Prediction correct? Sort of (within 1Â°C) â†’ is_correct = 1

Device_1:
  â”œâ”€ Actual reading: 71.8Â°C
  â”œâ”€ Model prediction: 75.2Â°C â† WAY OFF!
  â”œâ”€ Difference: 3.4Â°C â† BIG ERROR
  â””â”€ Prediction correct? NO â†’ is_correct = 0

â†“ After 1000 predictions:

Accuracy = (750 correct) / (1000 total) = 75%

This is REAL accuracy! Not a formula!
```

---

## What model_evaluations Table Contains

```sql
-- Current contents (after Spark ran):

SELECT * FROM model_evaluations ORDER BY evaluation_timestamp DESC LIMIT 10;

  model_version | device_id | prediction_result | actual_result | is_correct | model_accuracy | confidence
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  1             | device_0  | 0.85             | 0.92          | false      | 0.75           | 0.92
  1             | device_1  | 0.72             | 0.68          | true       | 0.75           | 0.72
  1             | device_234| 0.91             | 0.89          | true       | 0.75           | 0.91
  1             | device_2  | 0.45             | 0.51          | false      | 0.75           | 0.51
  1             | device_3  | 0.78             | 0.77          | true       | 0.75           | 0.78
  2             | device_0  | 0.88             | 0.92          | false      | 0.78           | 0.92
  2             | device_1  | 0.75             | 0.68          | false      | 0.78           | 0.75
  2             | device_234| 0.93             | 0.89          | true       | 0.78           | 0.93
  2             | device_2  | 0.47             | 0.51          | true       | 0.78           | 0.51
  2             | device_3  | 0.80             | 0.77          | true       | 0.78           | 0.80

-- REAL accuracies improving from v1 to v2!
-- v1: 75% (3 correct out of 5 shown)
-- v2: 78% (3 correct out of 5 shown, but better predictions)
```

---

## Key Insight: What Spark ACTUALLY Knows

```
Spark has access to:
â”œâ”€ Real sensor readings from 2,407 devices âœ“
â”œâ”€ Global model predictions âœ“
â”œâ”€ Time series data (24+ hours of history) âœ“
â”œâ”€ Ground truth comparisons âœ“
â”œâ”€ Error distribution âœ“
â””â”€ What errors the model makes most often âœ“

But currently:
â”œâ”€ Stores all this in model_evaluations âœ“
â”œâ”€ Calculates real accuracy âœ“
â””â”€ ... NEVER SENDS BACK TO FLINK âœ—

This is the missing link!
```

---

## How Spark's Stream Windowing Works

```
TIME FLOW (left to right):
10:30:00 â”€â”€â”€â”€â”€â”€â”€ 10:30:30 â”€â”€â”€â”€â”€â”€â”€ 10:31:00 â”€â”€â”€â”€â”€â”€â”€ 10:31:30

Devices sending continuously: â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“ â†“


WINDOW 1 (10:30:00 - 10:30:30):
Contains: All data in those 30 seconds
â”œâ”€ device_0: 45 readings
â”œâ”€ device_1: 43 readings
â”œâ”€ device_234: 46 readings
â””â”€ ... all devices

Aggregates:
â”œâ”€ Average temperature in window 1
â”œâ”€ Std deviation (spread of temperatures)
â””â”€ Calculate Z-scores


WINDOW 2 (10:30:30 - 10:31:00):
New 30-second window
Contains: All data in those 30 seconds (new readings)

Aggregates:
â”œâ”€ Average temperature in window 2
â”œâ”€ Std deviation in window 2
â””â”€ New Z-scores


â†’ This creates CONTINUOUS EVALUATION
â†’ Model being tested every 30 seconds!
â†’ Real-time feedback of how well predictions are
```

---

## Why Federated Server SHOULD Use This Data

### Current (WRONG):

```
Federated Server:
â”œâ”€ Receives 20 local models
â”œâ”€ Local model 1 accuracy: 72% (fake formula)
â”œâ”€ Local model 2 accuracy: 72% (fake formula)
â”œâ”€ ...
â”œâ”€ Local model 20 accuracy: 72% (fake formula)
â”œâ”€
â””â”€ Average = (72 + 72 + ... + 72) / 20 = 72%
   â†’ Global v1 accuracy = 72%

Next round:
â””â”€ Average = (74 + 74 + ... + 74) / 20 = 74%
   â†’ Global v2 accuracy = 74%

PROBLEM: Just averaging fake numbers!
```

### What It Should Do (RIGHT):

```
Federated Server:
â”œâ”€ Receives 20 local models (updated with real feedback)
â”œâ”€
â”œâ”€ Queries Spark: "What was global v1's REAL accuracy?"
â”‚  â””â”€ Result: 75% (based on 1000+ predictions vs actual data)
â”‚
â”œâ”€ Queries Spark: "What errors did v1 make most?"
â”‚  â””â”€ Result: Overpredicts anomalies, underpredicts normal
â”‚
â”œâ”€ Updates next global model with:
â”‚  â”œâ”€ Weights from local models
â”‚  â”œâ”€ REAL accuracy feedback: 75%
â”‚  â””â”€ Error patterns to fix
â”‚
â””â”€ Global v2 uses this to train better!

Next round:
â”œâ”€ Queries Spark: "What was global v2's REAL accuracy?"
â”‚  â””â”€ Result: 78% (improved from 75%!)
â”‚
â””â”€ v3 will improve even more based on v2's feedback
```

---

## The Chain Reaction (What Should Happen)

```
v1 created:
â”œâ”€ Flink trains 2,407 local models
â”œâ”€ Federated aggregates them
â””â”€ Creates global v1

Spark evaluates v1:
â”œâ”€ Makes predictions on stream data
â”œâ”€ Compares to actual values
â”œâ”€ Records 75% accuracy in model_evaluations â† REAL DATA!
â””â”€ Identifies error patterns

Feedback goes back:
â”œâ”€ Flink learns: v1 was 75% accurate, not 72%!
â”œâ”€ Identifies: v1 overpredicts anomalies
â””â”€ Trains v2 to fix those specific errors

v2 created (improved):
â”œâ”€ Flink trains using feedback from v1
â”œâ”€ Federated aggregates improved models
â””â”€ Creates global v2

Spark evaluates v2:
â”œâ”€ Makes predictions
â”œâ”€ Compares to actual
â”œâ”€ Records 78% accuracy â† IMPROVING! âœ“
â””â”€ Identifies remaining error patterns

Feedback goes back:
â”œâ”€ Flink learns: v2 was 78%, up from 75%!
â”œâ”€ Identifies new error patterns to fix
â””â”€ Trains v3 to fix those

v3 created (even better):
â””â”€ Cycle continues... 80% â†’ 82% â†’ 84%...
```

---

## Summary: What Spark is Really Doing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SPARK = REAL-TIME EVALUATION & GROUND TRUTH AUTHORITY         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Input:  Global model predictions + actual sensor data         â”‚
â”‚  Process: Calculate if predictions match reality                â”‚
â”‚  Output:  REAL accuracy metrics stored in database              â”‚
â”‚                                                                 â”‚
â”‚  Current problem: Results stored but never used!               â”‚
â”‚  Solution: Send results back to Flink in feedback loop         â”‚
â”‚                                                                 â”‚
â”‚  Spark is THE SOURCE OF TRUTH for model performance!           â”‚
â”‚  It's the only thing that knows if model is actually improving!â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Next Step

To make this work, we need:

1. **Create feedback topic** in Kafka: `model-feedback`
2. **Spark writes** to this topic with real evaluation results
3. **Flink reads** from this topic and adjusts training
4. **Loop repeats** with real improvement!

This is what Level 3 (Closed-Loop) does!
