{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17ccc185",
      "metadata": {
        "id": "17ccc185"
      },
      "source": [
        "**# FLEAD: Offline Federated Learning Simulation with the Edge-IIoTset Dataset**\n",
        "\n",
        "This notebook provides an offline simulation of the FLEAD project's core machine learning pipeline. It uses the `Edge-IIoTset` dataset to demonstrate the end-to-end process of training a federated Long Short-Term Memory (LSTM) model for anomaly detection.\n",
        "\n",
        "### Process Overview\n",
        "\n",
        "The simulation executes the following key steps:\n",
        "\n",
        "*   **Data Loading & Preprocessing:** Loads the `Edge-IIoTset` CSV and transforms the time series data into sequential windows suitable for an LSTM model.\n",
        "\n",
        "*   **Federated Partitioning:** Distributes the data windows among multiple simulated clients, supporting both IID and non-IID (time-skewed) distributions.\n",
        "\n",
        "*   **Federated Training:** Implements the Federated Averaging (FedAvg) algorithm to iteratively:\n",
        "    1.  Train local LSTM models on each client's data subset.\n",
        "    2.  Aggregate model updates to produce an improved global model.\n",
        "\n",
        "*   **Classification Modes:** Supports two distinct, configurable modes:\n",
        "    1.  **Binary:** (Benign vs. Attack) using the `Attack_label` column.\n",
        "    2.  **Multi-Class:** (Specific Attack Type) using the `Attack_type` column.\n",
        "\n",
        "*   **Evaluation & Visualization:** Tracks the global model's performance (accuracy and loss) after each round and visualizes the learning progress.\n",
        "\n",
        "**### Note on Scope**\n",
        "\n",
        "This notebook focuses exclusively on the data science and federated learning components for understanding purposes. For this simulation, distributed data streaming technologies such as Apache Kafka and Apache Flink are not implemented."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Install & set up Kaggle API\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "# Prompt for API token upload\n",
        "print(\"‚û°Ô∏è Please upload your kaggle.json (from Kaggle > Account > Create New API Token)\")\n",
        "files.upload()\n",
        "\n",
        "# Move the token to the correct directory and set permissions\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "print(\"‚úÖ Kaggle API configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "KS5SDI7MetRI",
        "outputId": "6439fe61-c3da-47e9-89a0-bf5a19a176ba"
      },
      "id": "KS5SDI7MetRI",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚û°Ô∏è Please upload your kaggle.json (from Kaggle > Account > Create New API Token)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-68c4b12c-fdad-446e-a770-4768619c8a05\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-68c4b12c-fdad-446e-a770-4768619c8a05\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "‚úÖ Kaggle API configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Download, unzip, and select the correct dataset\n",
        "!kaggle datasets download -d sibasispradhan/edge-iiotset-dataset -p /content/edge_iiot -q\n",
        "!unzip -q -o /content/edge_iiot/edge-iiotset-dataset.zip -d /content/edge_iiot\n",
        "print(\"‚úÖ Dataset downloaded and unzipped.\")\n",
        "\n",
        "import pathlib\n",
        "\n",
        "data_dir = pathlib.Path(\"/content/edge_iiot\")\n",
        "\n",
        "# As per the creators' research paper, we used their main pre-processed files.\n",
        "#'DNN-EdgeIIoT-dataset.csv' is specified for Deep Learning models (our goal).\n",
        "#'ML-EdgeIIoT-dataset.csv' is the designated backup.\n",
        "# Explicitly ignored other undocumented files (like live_data_training.csv) to ensure valid results.\n",
        "preferred_order = [\"DNN-EdgeIIoT-dataset.csv\", \"ML-EdgeIIoT-dataset.csv\"]\n",
        "CSV_PATH = None\n",
        "\n",
        "# Find the best available dataset from our corrected list.\n",
        "for name in preferred_order:\n",
        "    # Use rglob to find the file even if it's nested in a subfolder.\n",
        "    found_files = list(data_dir.rglob(name))\n",
        "    if found_files:\n",
        "        CSV_PATH = str(found_files[0])\n",
        "        break # Stop as soon as the best option is found.\n",
        "\n",
        "# --- Final Confirmation ---\n",
        "print(\"-\" * 50)\n",
        "if CSV_PATH:\n",
        "    selected_file = pathlib.Path(CSV_PATH).name\n",
        "    # NEW LOGIC: Check if the selected file was the top priority.\n",
        "    if selected_file == preferred_order[0]:\n",
        "        print(f\"‚úÖ Successfully selected the primary dataset: {selected_file}\")\n",
        "        print(\"(Backup dataset 'ML-EdgeIIoT-dataset.csv' was found but not needed).\")\n",
        "    else:\n",
        "        # This means the primary was not found, and we are using the backup.\n",
        "        print(f\"‚ö†Ô∏è Warning: Primary dataset '{preferred_order[0]}' not found.\")\n",
        "        print(f\"‚û°Ô∏è Using the designated backup dataset: {selected_file}\")\n",
        "else:\n",
        "    # This error is important. We can't proceed without a valid dataset.\n",
        "    print(\"‚ùå ERROR: Neither the DNN nor the ML dataset file could be found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1VK0kz1gWKH",
        "outputId": "08544c7e-c5e6-4174-b133-9258c7c26f81"
      },
      "id": "G1VK0kz1gWKH",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sibasispradhan/edge-iiotset-dataset\n",
            "License(s): MIT\n",
            "‚úÖ Dataset downloaded and unzipped.\n",
            "--------------------------------------------------\n",
            "‚úÖ Successfully selected the primary dataset: DNN-EdgeIIoT-dataset.csv\n",
            "(Backup dataset 'ML-EdgeIIoT-dataset.csv' was found but not needed).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3f665e38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f665e38",
        "outputId": "4cee6eb0-5958-4d5c-cf6c-eddb321300aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ TensorFlow version: 2.19.0\n",
            "‚úÖ GPU is available.\n"
          ]
        }
      ],
      "source": [
        "# === Core Libraries ===\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === Scikit-learn for Preprocessing & Evaluation ===\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# === TensorFlow for Deep Learning ===\n",
        "# We only need the main tensorflow import. Keras is accessible via tf.keras.\n",
        "import tensorflow as tf\n",
        "\n",
        "# === Reproducibility ===\n",
        "# Set a seed for random number generators in all libraries to ensure\n",
        "# that results can be reproduced on subsequent runs.\n",
        "SEED = 42\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Optional: Aims for more deterministic TF operations\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# === Environment Check ===\n",
        "print(f\"‚úÖ TensorFlow version: {tf.__version__}\")\n",
        "\n",
        "# Check for GPU availability for hardware acceleration\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"‚úÖ GPU is available.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected. Training will run on the CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "69ffd806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ffd806",
        "outputId": "fdfc43c2-2e32-4a33-a5f5-f2b2d60d2431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded successfully.\n",
            "Federated Learning: 4 clients, 5 rounds.\n",
            "Task: Binary classification.\n",
            "Time Series Window Size: 20 steps.\n"
          ]
        }
      ],
      "source": [
        "# === Configuration ===\n",
        "\n",
        "# --- CRITICAL FIX ---\n",
        "# The CSV_PATH is now automatically set by the previous cell.\n",
        "# We DO NOT redefine it here. This ensures we always use the correct, programmatically found file.\n",
        "# If you need to see the path, you can run: print(CSV_PATH)\n",
        "\n",
        "# --- NEW: Time Series Parameters ---\n",
        "# These are essential for preparing the data for the LSTM model.\n",
        "SEQUENCE_LENGTH  = 20    # The number of time steps in each sample (window size).\n",
        "TIME_COLUMN_NAME = None  # Set to the name of the timestamp column, e.g., 'frame.time', or None if we use row order.\n",
        "\n",
        "# --- Federated Learning Setup ---\n",
        "NUM_CLIENTS   = 4     # Number of simulated edge devices (clients).\n",
        "ROUNDS        = 5     # Number of global communication rounds.\n",
        "LOCAL_EPOCHS  = 2     # Local training epochs per client before aggregation.\n",
        "BATCH_SIZE    = 256   # Mini-batch size for each client's local training.\n",
        "IID_SPLIT     = True  # True = IID (randomly shuffled data); False = non-IID (clients get sequential time chunks).\n",
        "\n",
        "# --- Task & Model Architecture Setup ---\n",
        "# Set MULTICLASS to True to use 'Attack_type', False to use 'Attack_label'.\n",
        "MULTICLASS    = False #(For testing pursoses will be changed later)\n",
        "N_FEATURES    = None  # Will be set automatically after loading data.\n",
        "NUM_CLASSES   = None  # Will be set automatically based on the label column.\n",
        "\n",
        "# Neural network hyperparameters\n",
        "HIDDEN_UNITS  = [128, 64, 32] # Hidden layer sizes for the LSTM/Dense network.\n",
        "DROPOUT       = 0.2         # Dropout rate for regularization.\n",
        "LR            = 1e-3        # Learning rate for the Adam optimizer.\n",
        "\n",
        "# --- Confirmation ---\n",
        "print(\"‚úÖ Configuration loaded successfully.\")\n",
        "print(f\"Federated Learning: {NUM_CLIENTS} clients, {ROUNDS} rounds.\")\n",
        "print(f\"Task: {'Multi-class' if MULTICLASS else 'Binary'} classification.\")\n",
        "print(f\"Time Series Window Size: {SEQUENCE_LENGTH} steps.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "bc4e1d7c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "bc4e1d7c",
        "outputId": "4924efad-01fb-4106-cc05-883598cf4bd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in BINARY mode. Using label column: 'Attack_label'\n",
            "‚ö†Ô∏è No time column specified or found. Using original row order.\n",
            "--------------------------------------------------\n",
            "‚úÖ Data preparation complete.\n",
            "Features (X) shape: (2219201, 42)\n",
            "Labels (y) shape: (2219201,)\n",
            "Number of features detected: 42\n",
            "Number of classes detected: 2\n",
            "--------------------------------------------------\n",
            "Data Head:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  frame.time    ip.src_host    ip.dst_host arp.dst.proto_ipv4  \\\n",
              "0   2021 11:44:10.081753000   192.168.0.128  192.168.0.101                  0   \n",
              "1   2021 11:44:10.162218000   192.168.0.101  192.168.0.128                  0   \n",
              "2   2021 11:44:10.162271000   192.168.0.128  192.168.0.101                  0   \n",
              "\n",
              "   arp.opcode  arp.hw.size arp.src.proto_ipv4  icmp.checksum  icmp.seq_le  \\\n",
              "0         0.0          0.0                  0            0.0          0.0   \n",
              "1         0.0          0.0                  0            0.0          0.0   \n",
              "2         0.0          0.0                  0            0.0          0.0   \n",
              "\n",
              "   icmp.transmit_timestamp  ...  mqtt.protoname mqtt.topic  mqtt.topic_len  \\\n",
              "0                      0.0  ...               0          0             0.0   \n",
              "1                      0.0  ...            MQTT          0             0.0   \n",
              "2                      0.0  ...               0          0             0.0   \n",
              "\n",
              "  mqtt.ver mbtcp.len mbtcp.trans_id mbtcp.unit_id Attack_label  Attack_type  \\\n",
              "0      0.0       0.0            0.0           0.0            0       Normal   \n",
              "1      4.0       0.0            0.0           0.0            0       Normal   \n",
              "2      0.0       0.0            0.0           0.0            0       Normal   \n",
              "\n",
              "   label_encoded  \n",
              "0              0  \n",
              "1              0  \n",
              "2              0  \n",
              "\n",
              "[3 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-53e71dbf-48e6-4ef8-aabf-e02f11d85e56\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frame.time</th>\n",
              "      <th>ip.src_host</th>\n",
              "      <th>ip.dst_host</th>\n",
              "      <th>arp.dst.proto_ipv4</th>\n",
              "      <th>arp.opcode</th>\n",
              "      <th>arp.hw.size</th>\n",
              "      <th>arp.src.proto_ipv4</th>\n",
              "      <th>icmp.checksum</th>\n",
              "      <th>icmp.seq_le</th>\n",
              "      <th>icmp.transmit_timestamp</th>\n",
              "      <th>...</th>\n",
              "      <th>mqtt.protoname</th>\n",
              "      <th>mqtt.topic</th>\n",
              "      <th>mqtt.topic_len</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mbtcp.len</th>\n",
              "      <th>mbtcp.trans_id</th>\n",
              "      <th>mbtcp.unit_id</th>\n",
              "      <th>Attack_label</th>\n",
              "      <th>Attack_type</th>\n",
              "      <th>label_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021 11:44:10.081753000</td>\n",
              "      <td>192.168.0.128</td>\n",
              "      <td>192.168.0.101</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021 11:44:10.162218000</td>\n",
              "      <td>192.168.0.101</td>\n",
              "      <td>192.168.0.128</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>MQTT</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021 11:44:10.162271000</td>\n",
              "      <td>192.168.0.128</td>\n",
              "      <td>192.168.0.101</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows √ó 64 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-53e71dbf-48e6-4ef8-aabf-e02f11d85e56')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-53e71dbf-48e6-4ef8-aabf-e02f11d85e56 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-53e71dbf-48e6-4ef8-aabf-e02f11d85e56');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7dc0ebf3-8032-4a4e-90ef-11a925b6ff6b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dc0ebf3-8032-4a4e-90ef-11a925b6ff6b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7dc0ebf3-8032-4a4e-90ef-11a925b6ff6b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# === Data Loading and Preparation ===\n",
        "\n",
        "# 1. Load the dataset using the path set by our file-finder logic\n",
        "assert os.path.exists(CSV_PATH), f\"‚ùå File not found: {CSV_PATH}\"\n",
        "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
        "\n",
        "# 2. Handle Labels based on the MULTICLASS configuration switch\n",
        "if MULTICLASS:\n",
        "    LABEL_COL_NAME = 'Attack_type'\n",
        "    print(f\"Running in MULTI-CLASS mode. Using label column: '{LABEL_COL_NAME}'\")\n",
        "    encoder = LabelEncoder()\n",
        "    df['label_encoded'] = encoder.fit_transform(df[LABEL_COL_NAME])\n",
        "else:\n",
        "    LABEL_COL_NAME = 'Attack_label'\n",
        "    print(f\"Running in BINARY mode. Using label column: '{LABEL_COL_NAME}'\")\n",
        "    df['label_encoded'] = df[LABEL_COL_NAME]\n",
        "\n",
        "# 3. Sort by Time (if a time column is specified and exists)\n",
        "if TIME_COLUMN_NAME and TIME_COLUMN_NAME in df.columns:\n",
        "    print(f\"üïí Converting and sorting by time column: {TIME_COLUMN_NAME}\")\n",
        "\n",
        "    # --- THE DEFINITIVE FIX ---\n",
        "    # Step A: First, force the column to a numeric type. Any non-number text becomes NaN.\n",
        "    numeric_timestamps = pd.to_numeric(df[TIME_COLUMN_NAME], errors='coerce')\n",
        "\n",
        "    # Step B: Now, convert the clean numbers (Unix timestamps) to datetime objects.\n",
        "    df[TIME_COLUMN_NAME] = pd.to_datetime(numeric_timestamps, unit='s', errors='coerce')\n",
        "\n",
        "    # Step C: Drop any rows that failed conversion and then sort the rest.\n",
        "    df.dropna(subset=[TIME_COLUMN_NAME], inplace=True)\n",
        "    df.sort_values(TIME_COLUMN_NAME, inplace=True)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No time column specified or found. Using original row order.\")\n",
        "\n",
        "# 4. Separate Features (X) and Labels (y)\n",
        "potential_label_cols = ['Attack_label', 'Attack_type', 'label_encoded']\n",
        "feature_cols = [col for col in df.columns if df[col].dtype in ['float64', 'int64'] and col not in potential_label_cols]\n",
        "X = df[feature_cols].astype(np.float32)\n",
        "y = df['label_encoded'].values\n",
        "\n",
        "# 5. Finalize and Update Dynamic Configuration\n",
        "N_FEATURES = X.shape[1]\n",
        "NUM_CLASSES = len(np.unique(y))\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"-\" * 50)\n",
        "print(f\"‚úÖ Data preparation complete.\")\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Labels (y) shape: {y.shape}\")\n",
        "print(f\"Number of features detected: {N_FEATURES}\")\n",
        "print(f\"Number of classes detected: {NUM_CLASSES}\")\n",
        "if MULTICLASS:\n",
        "    print(f\"Class mapping: {list(encoder.classes_)}\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Data Head:\")\n",
        "display(df.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d5ed2525",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ed2525",
        "outputId": "e6dce3c6-114c-45aa-c597-8bf89940fc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using a 10.0% subset for this simulation.\n",
            "  - Dev Training set size: 177536 rows.\n",
            "  - Dev Testing set size:  44384 rows.\n",
            "\n",
            "‚úÖ Subsets created and scaled successfully.\n",
            "--------------------------------------------------\n",
            "‚úÖ Time series sequences created from subsets.\n",
            "Final training features shape: (177517, 20, 42)\n",
            "Final testing features shape:  (44365, 20, 42)\n",
            "\n",
            "‚û°Ô∏è Model input shape will be: (20, 42)\n"
          ]
        }
      ],
      "source": [
        "# === Final Data Prep Part 1: Split, Subset, Scale, and Window ===\n",
        "\n",
        "# 1. Split the full data into initial Training and Testing sets (chronological)\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False, random_state=SEED\n",
        ")\n",
        "\n",
        "# 2. --- CRITICAL FIX: Create a smaller subset from BOTH sets to prevent crashes ---\n",
        "DEV_SET_FRACTION = 0.1 # Use 10% of the data for this simulation\n",
        "train_subset_size = int(len(X_train_full) * DEV_SET_FRACTION)\n",
        "test_subset_size = int(len(X_test_full) * DEV_SET_FRACTION)\n",
        "\n",
        "X_train_dev = X_train_full[:train_subset_size]\n",
        "y_train_dev = y_train_full[:train_subset_size]\n",
        "X_test_dev = X_test_full[:test_subset_size]\n",
        "y_test_dev = y_test_full[:test_subset_size]\n",
        "\n",
        "print(f\"Using a {DEV_SET_FRACTION*100}% subset for this simulation.\")\n",
        "print(f\"  - Dev Training set size: {len(X_train_dev)} rows.\")\n",
        "print(f\"  - Dev Testing set size:  {len(X_test_dev)} rows.\\n\")\n",
        "\n",
        "# 3. Scale the feature data (fitting ONLY on the training subset)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_dev)\n",
        "X_test_scaled = scaler.transform(X_test_dev)\n",
        "print(\"‚úÖ Subsets created and scaled successfully.\")\n",
        "\n",
        "# 4. Create time series sequences (windows) from the smaller subsets\n",
        "def create_sequences(features, labels, seq_length):\n",
        "    \"\"\"Creates overlapping sequences from time series data.\"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(features) - seq_length + 1):\n",
        "        X_seq.append(features[i:(i + seq_length)])\n",
        "        y_seq.append(labels[i + seq_length - 1])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_dev, SEQUENCE_LENGTH)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_dev, SEQUENCE_LENGTH)\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"-\" * 50)\n",
        "print(\"‚úÖ Time series sequences created from subsets.\")\n",
        "print(f\"Final training features shape: {X_train_seq.shape}\")\n",
        "print(f\"Final testing features shape:  {X_test_seq.shape}\")\n",
        "\n",
        "INPUT_SHAPE = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
        "print(f\"\\n‚û°Ô∏è Model input shape will be: {INPUT_SHAPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "47e98f86",
      "metadata": {
        "id": "47e98f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "142fc814-813f-4ccc-ac2f-8b9e5343d6d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using a stratified 2.0% subset for training.\n",
            "  - Dev Training set size: 35508 rows.\n",
            "  - Dev Testing set size:  8876 rows.\n",
            "\n",
            "‚úÖ Subsets created and scaled successfully.\n",
            "--------------------------------------------------\n",
            "‚úÖ Time series sequences created from subsets.\n",
            "Final training features shape: (35489, 20, 42)\n",
            "Final testing features shape:  (8857, 20, 42)\n",
            "\n",
            "‚û°Ô∏è Model input shape will be: (20, 42)\n"
          ]
        }
      ],
      "source": [
        "# === Final Data Prep Part 1: Split, Stratified Subset, Scale, and Window ===\n",
        "\n",
        "# 1. Split the full data into initial Training and Testing sets (chronological)\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=False, random_state=SEED\n",
        ")\n",
        "\n",
        "# 2. --- STRATIFIED subset to ensure both classes are present ---\n",
        "DEV_SET_FRACTION = 0.02 # Use 2% of the data for this simulation\n",
        "\n",
        "# Use train_test_split again to create a smaller, representative subset.\n",
        "# 'stratify=y_train_full' is the key: it preserves the percentage of each class.\n",
        "_, X_train_dev, _, y_train_dev = train_test_split(\n",
        "    X_train_full, y_train_full,\n",
        "    test_size=DEV_SET_FRACTION,\n",
        "    shuffle=True, # Shuffle is needed for a random representative sample\n",
        "    stratify=y_train_full,\n",
        "    random_state=SEED\n",
        ")\n",
        "\n",
        "# We still use a simple chronological subset for the test data\n",
        "test_subset_size = int(len(X_test_full) * DEV_SET_FRACTION)\n",
        "X_test_dev = X_test_full[:test_subset_size]\n",
        "y_test_dev = y_test_full[:test_subset_size]\n",
        "\n",
        "print(f\"Using a stratified {DEV_SET_FRACTION*100}% subset for training.\")\n",
        "print(f\"  - Dev Training set size: {len(X_train_dev)} rows.\")\n",
        "print(f\"  - Dev Testing set size:  {len(X_test_dev)} rows.\\n\")\n",
        "\n",
        "# 3. Scale the feature data (fitting ONLY on the training subset)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_dev)\n",
        "X_test_scaled = scaler.transform(X_test_dev)\n",
        "print(\"‚úÖ Subsets created and scaled successfully.\")\n",
        "\n",
        "# 4. Create time series sequences (windows)\n",
        "def create_sequences(features, labels, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(features) - seq_length + 1):\n",
        "        X_seq.append(features[i:(i + seq_length)])\n",
        "        y_seq.append(labels[i + seq_length - 1])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_dev, SEQUENCE_LENGTH)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_dev, SEQUENCE_LENGTH)\n",
        "\n",
        "# --- Summary ---\n",
        "print(\"-\" * 50)\n",
        "print(\"‚úÖ Time series sequences created from subsets.\")\n",
        "print(f\"Final training features shape: {X_train_seq.shape}\")\n",
        "print(f\"Final testing features shape:  {X_test_seq.shape}\")\n",
        "INPUT_SHAPE = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
        "print(f\"\\n‚û°Ô∏è Model input shape will be: {INPUT_SHAPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Final Data Prep Part 2: Create Federated Clients ===\n",
        "\n",
        "def create_federated_clients(X, y, num_clients, iid=True):\n",
        "    \"\"\"Partitions the training data among a number of simulated clients.\"\"\"\n",
        "    client_data = {}\n",
        "    all_indices = np.arange(len(X))\n",
        "\n",
        "    if iid:\n",
        "        np.random.shuffle(all_indices)\n",
        "        print(\"Creating an IID data split (data is shuffled)...\")\n",
        "    else:\n",
        "        print(\"Creating a non-IID data split (clients get sequential time chunks)...\")\n",
        "\n",
        "    client_indices = np.array_split(all_indices, num_clients)\n",
        "\n",
        "    for i in range(num_clients):\n",
        "        client_X = X[client_indices[i]]\n",
        "        client_y = y[client_indices[i]]\n",
        "        client_data[f'client_{i+1}'] = (client_X, client_y)\n",
        "\n",
        "    return client_data\n",
        "\n",
        "# Create the client data using the balanced, subsetted training sequences\n",
        "federated_train_data = create_federated_clients(\n",
        "    X_train_seq, y_train_seq, NUM_CLIENTS, iid=IID_SPLIT\n",
        ")\n",
        "\n",
        "# --- Summary of the Federated Data Split ---\n",
        "print(\"-\" * 50)\n",
        "print(f\"‚úÖ Successfully created {len(federated_train_data)} federated clients.\")\n",
        "for i in range(NUM_CLIENTS):\n",
        "    client_id = f'client_{i+1}'\n",
        "    client_X, client_y = federated_train_data[client_id]\n",
        "\n",
        "    # This line will now show the proof of stratification\n",
        "    label_counts = np.bincount(client_y, minlength=NUM_CLASSES)\n",
        "\n",
        "    print(f\"  - {client_id}: X shape = {client_X.shape}, Label distribution = {label_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW3CXXFQUPl_",
        "outputId": "93f128b3-d201-4134-8c03-332ca9ecf42f"
      },
      "id": "iW3CXXFQUPl_",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating an IID data split (data is shuffled)...\n",
            "--------------------------------------------------\n",
            "‚úÖ Successfully created 4 federated clients.\n",
            "  - client_1: X shape = (8873, 20, 42), Label distribution = [8095  778]\n",
            "  - client_2: X shape = (8872, 20, 42), Label distribution = [8086  786]\n",
            "  - client_3: X shape = (8872, 20, 42), Label distribution = [8067  805]\n",
            "  - client_4: X shape = (8872, 20, 42), Label distribution = [8048  824]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "60e2c1fd",
      "metadata": {
        "id": "60e2c1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "ec48b91e-56f4-4059-a0ef-2ae41c79faa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ LSTM model created successfully.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m42\u001b[0m)         ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_10 (\u001b[38;5;33mLSTM\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        ‚îÇ        \u001b[38;5;34m87,552\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)        ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_11 (\u001b[38;5;33mLSTM\u001b[0m)                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             ‚îÇ        \u001b[38;5;34m49,408\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ         \u001b[38;5;34m2,080\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_15 (\u001b[38;5;33mDropout\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             ‚îÇ             \u001b[38;5;34m0\u001b[0m ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              ‚îÇ            \u001b[38;5;34m33\u001b[0m ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
              "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
              "‚îÇ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)         ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">87,552</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ lstm_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             ‚îÇ        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dropout_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
              "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
              "‚îÇ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> ‚îÇ\n",
              "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m139,073\u001b[0m (543.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,073</span> (543.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m139,073\u001b[0m (543.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">139,073</span> (543.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# === Define the LSTM Model Architecture ===\n",
        "\n",
        "def create_lstm_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Creates, compiles, and returns a Keras LSTM model using the Functional API.\n",
        "    \"\"\"\n",
        "    # --- NEW: Add a check to prevent the cryptic ValueError ---\n",
        "    # This gives a clear error if the data prep cell didn't run correctly.\n",
        "    assert num_classes is not None, \"NUM_CLASSES is None. Please re-run the 'Final Data Prep' cell before this one.\"\n",
        "    assert input_shape is not None, \"INPUT_SHAPE is None. Please re-run the 'Final Data Prep' cell before this one.\"\n",
        "\n",
        "    # Define the input layer\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "\n",
        "    # --- Hidden Layers ---\n",
        "    x = tf.keras.layers.LSTM(HIDDEN_UNITS[0], return_sequences=True)(inputs)\n",
        "    x = tf.keras.layers.Dropout(DROPOUT)(x)\n",
        "\n",
        "    x = tf.keras.layers.LSTM(HIDDEN_UNITS[1])(x)\n",
        "    x = tf.keras.layers.Dropout(DROPOUT)(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(HIDDEN_UNITS[2])(x)\n",
        "    x = tf.keras.layers.Dropout(DROPOUT)(x)\n",
        "\n",
        "    # --- Dynamic Output Layer ---\n",
        "    if num_classes == 2:\n",
        "        outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "        loss_function = 'binary_crossentropy'\n",
        "    else:\n",
        "        outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "        loss_function = 'sparse_categorical_crossentropy'\n",
        "\n",
        "    # --- Create and Compile the Model ---\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss_function,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the global model to initialize it and see its structure\n",
        "global_model = create_lstm_model(INPUT_SHAPE, NUM_CLASSES)\n",
        "\n",
        "# --- Summary of the Model ---\n",
        "print(\"‚úÖ LSTM model created successfully.\")\n",
        "global_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b21d995b",
      "metadata": {
        "id": "b21d995b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37939364-7e03-47ed-c90e-ddf34fc14603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Round 1/5 ---\n",
            "  Training client_1...\n",
            "  Training client_2...\n",
            "  Training client_3...\n",
            "  Training client_4...\n",
            "  GLOBAL MODEL EVALUATION: Loss=1.3843, Accuracy=0.0000\n",
            "\n",
            "--- Round 2/5 ---\n",
            "  Training client_1...\n",
            "  Training client_2...\n",
            "  Training client_3...\n",
            "  Training client_4...\n",
            "  GLOBAL MODEL EVALUATION: Loss=1.0857, Accuracy=0.3579\n",
            "\n",
            "--- Round 3/5 ---\n",
            "  Training client_1...\n",
            "  Training client_2...\n",
            "  Training client_3...\n",
            "  Training client_4...\n",
            "  GLOBAL MODEL EVALUATION: Loss=0.5129, Accuracy=0.6583\n",
            "\n",
            "--- Round 4/5 ---\n",
            "  Training client_1...\n",
            "  Training client_2...\n",
            "  Training client_3...\n",
            "  Training client_4...\n",
            "  GLOBAL MODEL EVALUATION: Loss=0.1690, Accuracy=0.9904\n",
            "\n",
            "--- Round 5/5 ---\n",
            "  Training client_1...\n",
            "  Training client_2...\n",
            "  Training client_3...\n",
            "  Training client_4...\n",
            "  GLOBAL MODEL EVALUATION: Loss=0.1076, Accuracy=0.9922\n",
            "\n",
            "‚úÖ Federated training complete.\n"
          ]
        }
      ],
      "source": [
        "# === Implement the Federated Averaging (FedAvg) Loop ===\n",
        "\n",
        "# Create a history dictionary to store the performance of the global model after each round\n",
        "history = {'loss': [], 'accuracy': []}\n",
        "\n",
        "# This is the main federated learning loop\n",
        "for r in range(ROUNDS):\n",
        "    print(f\"\\n--- Round {r+1}/{ROUNDS} ---\")\n",
        "\n",
        "    # 1. LOCAL TRAINING on each client\n",
        "    local_model_weights = []\n",
        "    for client_id, (client_X, client_y) in federated_train_data.items():\n",
        "        local_model = create_lstm_model(INPUT_SHAPE, NUM_CLASSES)\n",
        "        local_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        print(f\"  Training {client_id}...\")\n",
        "        local_model.fit(client_X, client_y,\n",
        "                        epochs=LOCAL_EPOCHS,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        verbose=0)\n",
        "\n",
        "        local_model_weights.append(local_model.get_weights())\n",
        "\n",
        "    # 2. --- ROBUST GLOBAL AGGREGATION (THE FIX) ---\n",
        "\n",
        "    # Initialize a new list to hold the averaged weights\n",
        "    new_global_weights = []\n",
        "\n",
        "    # Get the number of layers in the model\n",
        "    num_layers = len(global_model.get_weights())\n",
        "\n",
        "    # Loop through each layer of the model\n",
        "    for i in range(num_layers):\n",
        "        # Get the weights for this specific layer from all clients\n",
        "        layer_weights = np.array([client_weights[i] for client_weights in local_model_weights], dtype=object)\n",
        "\n",
        "        # Calculate the average for this layer's weights\n",
        "        avg_layer_weights = np.mean(layer_weights, axis=0)\n",
        "\n",
        "        # Add the averaged weights for this layer to our new list\n",
        "        new_global_weights.append(avg_layer_weights)\n",
        "\n",
        "    # Set the global model's weights to this new averaged list\n",
        "    global_model.set_weights(new_global_weights)\n",
        "\n",
        "    # 3. GLOBAL EVALUATION\n",
        "    loss, acc = global_model.evaluate(X_test_seq, y_test_seq, verbose=0)\n",
        "\n",
        "    print(f\"  GLOBAL MODEL EVALUATION: Loss={loss:.4f}, Accuracy={acc:.4f}\")\n",
        "\n",
        "    history['loss'].append(loss)\n",
        "    history['accuracy'].append(acc)\n",
        "\n",
        "print(\"\\n‚úÖ Federated training complete.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}